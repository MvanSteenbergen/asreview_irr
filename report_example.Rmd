---
title: "ASReview report"
output:
  # word_document:
  #   toc: yes
  #   toc_depth: '3'
  html_document:
    toc: yes
    toc_depth: 3
    number_sections: true
    theme: united
    toc_float: true
---

This report is an example of the output from an [open source tool](https://github.com/langtonhugh/asreview_irr) which makes it easier to compare the decisions by two raters after screening literature samples in [ASReview](https://asreview.nl/). The report can be created automatically using the .csv files downloaded directly from the ASReview dashboard. The report is a work-in-progress. If you are an R user, please take a look at the [source code](https://github.com/langtonhugh/asreview_irr/blob/main/report_example.Rmd). Checks, feedback and suggestions for additional features are welcome. You can find my contact details on [my website](https://www.samlangton.info/).


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, warning = F, message = F)
# Load packages.
library(readr)
library(dplyr)
library(stringr)
library(purrr)
library(irr)
library(kableExtra)
library(waffle)
```

```{r start}
# Load data.
first_df <- read_csv("data/asreview_result_spatial-and-temporal-patterning-of-emergency-reactive-police-demand.csv")
secon_df <- read_csv("data/asreview_result_spatial-and-temporal-patterning-of-emergency-reactive-police-demand-2nd-coder.csv")

# Total reviewed.
first_total <- table(first_df$included)[["1"]] + table(first_df$included)[["0"]]
secon_total <- table(secon_df$included)[["1"]] + table(secon_df$included)[["0"]]

# Relevant flags.
first_rele <- table(first_df$included)[["1"]]
first_irre <- table(first_df$included)[["0"]]

# Irrelevant flags.
secon_rele <- table(secon_df$included)[["1"]]
secon_irre <- table(secon_df$included)[["0"]]

# Not reviewed
first_unrev <- sum(is.na(first_df$included))
secon_unrev <- sum(is.na(secon_df$included))

# % reviewed.
first_prev <- round(100*first_total/nrow(first_df), 2)
secon_prev <- round(100*secon_total/nrow(secon_df), 2)

# Total 'irrelevant' (if we define un-reviewed as irrelevant)
first_trele <- first_irre + first_unrev
secon_trele <- secon_irre + secon_unrev

# % total relevant out of all articles uploaded to asreview.
first_ptrel <- round(100*first_rele/nrow(first_df), 2)
secon_ptrel <- round(100*secon_rele/nrow(secon_df), 2)

# % flagged relevant (out of those reviewed).
first_pfrel <- round(100*first_rele/first_total, 2)
secon_pfrel <- round(100*secon_rele/secon_total, 2)

# Disagreements 1: first coder says relevant, second coder says irrelevant.
first_relevant_vec <- first_df %>%
  filter(included == 1) %>%
  pluck("record_id")

disagree1_df <- secon_df %>%
  filter(included == 0, record_id %in% first_relevant_vec) %>%
  # select(record_id, authors, year, title, abstract) # For newer projects.
  select(record_id, first_authors, publication_year, primary_title, notes_abstract) # For older projects.

# Define how many disagreements for table.
first_dis <- nrow(disagree1_df) # 39

# Disagreement 2: second coder says relevant, first coder says irrelevant, 
secon_relevant_vec <- secon_df %>% 
  filter(included == 1) %>% 
  pluck("record_id")

# Subset first rater's irrelevant list with those second rater said relevant.
disagree2_df <- first_df %>% 
  filter(included == 0, record_id %in% secon_relevant_vec) %>% 
  # select(record_id, authors, year, title, abstract) # For newer projects.
  select(record_id, first_authors, publication_year, primary_title, notes_abstract) # For older projects.

# Define how many disagreements for table.
secon_dis <- nrow(disagree2_df) # 5

# Sort and create vectors for Kappa.
first_vec <- first_df %>% 
  arrange(record_id) %>% 
  pluck("included")

secon_vec <- secon_df %>% 
  arrange(record_id) %>% 
  pluck("included")

# Create array for Kappa. Note this still contains missings for those that 
# one or both raters did not review. These are automatically removed in the stat.
# Not that the actual Kappa test is run within the script later.
full_array <- cbind(first_vec, secon_vec)

# Further disagreement statistics.

# Identify left unreviewed by rater 1.
first_dist_vec <- first_df %>% 
  filter(is.na(included)) %>%
  pluck("record_id")

# Check. This should be TRUE.
# length(first_dist_vec) == first_unrev

# Identify left unreviewed by rater 2.
secon_dist_vec <- secon_df %>% 
  filter(is.na(included)) %>%
  pluck("record_id")

# Check. This should be TRUE.
# length(secon_dist_vec) == secon_unrev

# Create flag for those identified as relevant by first rater, but not reviewed
# by second.
first_dist_df <- first_df %>% 
  filter(included == 1) %>% 
  mutate(missed_flag = if_else(record_id %in% secon_dist_vec,
                               "missed",
                               "not missed"),
         missed_flag = as.factor(missed_flag))

# Define the factor levels so we get frequencies of zeros, if there.
first_dist_df$missed_flag_fac <- factor(first_dist_df$missed_flag,
                                        levels = c("not missed", "missed"))

# Frequency counts.
# table(first_dist_df$missed_flag_fac)

# Create flag for those identified as relevant by second rater, but not reviewed
# by second.
secon_dist_df <- secon_df %>% 
  filter(included == 1) %>% 
  mutate(missed_flag = if_else(record_id %in% first_dist_vec,
                          "missed",
                          "not missed"),
         missed_flag = as.factor(missed_flag))

# Define the factor levels so we get frequencies of zeros, if there.
secon_dist_df$missed_flag_fac <- factor(secon_dist_df$missed_flag,
                                        levels = c("not missed", "missed"))

# Frequency counts.
# table(secon_dist_df$missed_flag_fac)

# Create vectors with numbers of missed for the table.
missed1 <- table(first_dist_df$missed_flag_fac)[["missed"]]
missed2 <- table(secon_dist_df$missed_flag_fac)[["missed"]]
```

```{r irrdatasave}
# This is just to save a nice table summary for a paper, not for the report.
irr_df <- tibble(
  ` ` = c("n uploaded", 
                "n reviewed",
                "% reviewed",
                "n flagged relevant",
                "n flagged irrelevant",
                "% flagged relevant",
                "n unreviewed",
                "n total irrelevant",
                "% total relevant",
                "n relevant v. irrelevant",
                "n relevant v. unreviewed"),
  `rater A` = c(nrow(first_df),
                first_total,
                first_prev,
                first_rele,
                first_irre,
                first_pfrel,
                first_unrev,
                first_trele,
                first_ptrel,
                first_dis,
                missed1),
  `rater B` = c(nrow(secon_df),
                secon_total,
                secon_prev,
                secon_rele,
                secon_irre,
                secon_pfrel,
                secon_unrev,
                secon_trele,
                secon_ptrel,
                secon_dis,
                missed2)
  )

write_csv(x = irr_df, file = "data/irr_table.csv")

```

# Rater summary

|                          | rater A            | rater B            |
| ------------------------ |:------------------:| ------------------:|
| n uploaded               | `r nrow(first_df)` | `r nrow(secon_df)` |
| n reviewed               | `r first_total`    | `r secon_total`    |
| % reviewed               | `r first_prev`     | `r secon_prev`     |
| n flagged relevant       | `r first_rele`     | `r secon_rele`     |
| n flagged irrelevant     | `r first_irre`     | `r secon_irre`     |
| % flagged relevant       | `r first_pfrel`    | `r secon_pfrel`    |
| n unreviewed             | `r first_unrev`    | `r secon_unrev`    |
| n total irrelevant       | `r first_trele`    | `r secon_trele`    |
| % total relevant         | `r first_ptrel`    | `r secon_ptrel`    |
| n relevant v. irrelevant | `r first_dis`      | `r secon_dis`      | 
| n relevant v. unreviewed | `r missed1`        | `r missed2`        | 

# Overall summary

```{r additionaltable}
# Remove the notes col
secon_df <- secon_df %>% 
  # select(-exported_notes_1) %>%      # add if needed.
  mutate(rater_id = 2) 
  # rename(record_id = `Ã¯..record_id`) # add if needed.

# Create rater id for the first rater.
first_df <- first_df %>% 
  mutate(rater_id = 1)

# Bind together.
first_secon_review_df <- bind_rows(first_df, secon_df) %>% 
  mutate(included_new = if_else(is.na(included), 1000, included))

# Create summary table.
compare_df <- first_secon_review_df %>% 
  # group_by(record_id, title) %>%       # add if needed. 
  group_by(record_id, first_authors, publication_year, primary_title, notes_abstract) %>% # comment out if needed.
  summarise(agreement_number = sum(included_new)) %>% 
  ungroup()

# Summary table.
table2_summary_df <- count(compare_df, agreement_number) %>%
  mutate(stat = ifelse(agreement_number == 0   , "Both rated irrelevant"                      , NA),
         stat = ifelse(agreement_number == 1   , "One rated relevant, other irrelevant"       , stat),
         stat = ifelse(agreement_number == 2   , "Both rated relevant"                        , stat),
         stat = ifelse(agreement_number == 1000, "One rated irrelevant, other left unreviewed", stat),
         stat = ifelse(agreement_number == 1001, "One rated relevant, other left unreviewed"  , stat),
         stat = ifelse(agreement_number == 2000, "Both left unreviewed"                       , stat)) %>% 
  select(stat, n) %>% 
  rename(Description = stat)

both_raters_df <- table2_summary_df %>% 
  filter(Description == "Both rated irrelevant" |
         Description == "One rated relevant, other irrelevant" |
         Description == "Both rated relevant") %>% 
  # group_by(Description) %>% 
  summarize(Description = "Both raters made decision",
            n = sum(n))

table2_summary_complete_df <- table2_summary_df %>% 
  bind_rows(both_raters_df)

kable(table2_summary_complete_df)
```

# Written explanations 

- Reviewer A evaluated `r first_total` of `r nrow(first_df)` articles (`r first_prev`%), of which (s)he flagged `r first_rele` as relevant and `r first_irre` as irrelevant.
- Reviewer B evaluated `r secon_total` of `r nrow(secon_df)` articles (`r secon_prev`%), of which (s)he flagged `r secon_rele` as relevant and `r secon_irre` as irrelevant.
- Rater A left a total of `r first_unrev` articles unreviewed, while rater B left `r secon_unrev` unreviewed. In other words, these articles lay beyond the 'stop rule' and were never seen by the raters.
- Rater A flagged `r missed1` article(s) as relevant that rater B left unreviewed. This figure for Rater B was `r missed2`. 
- The 'total irrelevant' figure is the sum of (1) the number of articles actively flagged as irrelevant by raters and (2) the number of articles left unreviewed after the stop rule (and therefore assumed to be irrelevant).
- Rater A flagged `r first_dis` articles as relevant that rater B flagged as irrelevant. Conversely, rater B flagged `r secon_dis` articles as relevant that rater B flagged as irrelevant.
- Here, the number of decisions eligible for the Kappa statistic is defined as the _both raters made decision_ figure. This is the sum of _both rated irrelevant_, _one rated relevant, other irrelevant_  and _both rated relevant_. By default, then, the Kappa reported here does not include abstracts for which _one rated relevant, other left unreviewed_. 

# Visual summary

## Proportional breakdown

<center>

```{r, propbreakdown}
first_secon_review_df %>% 
  group_by(rater_id, included_new) %>% 
  summarize(freq = n()) %>%
  mutate(rater_id     = if_else(rater_id == 1, "Rater A", "Rater B"),
         included_var = recode(included_new,
                               `0`    = "Irrelevant",
                               `1`    = "Relevant"  ,
                               `1000` = "Unreviewed")) %>% 
  ggplot(data = .) +
  geom_waffle(mapping = aes(fill = included_var, values = freq),
              color = "white", make_proportional = TRUE, n_rows = 5,
              alpha = 0.7, 
              size = 0.5) +
  facet_wrap(~rater_id, ncol = 1) +
  theme_void() +
  theme(axis.text  = element_blank(),
        axis.ticks = element_blank(),
        legend.position = "bottom",
        plot.title = element_text(hjust = 0.5, size = 12),
        legend.text = element_text(size = 9)) +
  labs(fill = NULL,
       title = "1 square = 1% of sample \n") +
  scale_fill_brewer(palette = "Set1") +
  coord_fixed(ratio = 1)
```

</center> 

## Rater overlap

<center>

```{r, overlap}
count(compare_df, agreement_number) %>%
  mutate(stat = ifelse(agreement_number == 0   , "Both rated irrelevant"                      , NA),
         stat = ifelse(agreement_number == 1   , "One rated relevant, other irrelevant"       , stat),
         stat = ifelse(agreement_number == 2   , "Both rated relevant"                        , stat),
         stat = ifelse(agreement_number == 1000, "One rated irrelevant, other left unreviewed", stat),
         stat = ifelse(agreement_number == 1001, "One rated relevant, other left unreviewed"  , stat),
         stat = ifelse(agreement_number == 2000, "Both left unreviewed"                       , stat)) %>% 
  select(stat, n) %>% 
  rename(Description = stat) %>% 
  ggplot(data = .) +
  geom_waffle(mapping = aes(fill = Description, values = n),
              make_proportional = FALSE,
              n_rows = 60,
              size = 0.5,
              alpha = 0.9,
              colour = "white",
              flip = TRUE)  +
  theme_void() +
  labs(fill = NULL, title = "1 square = 1 article") +
  scale_fill_brewer(palette = "Set2") +
  theme(legend.position = "right",
        axis.ticks = element_blank(),
        axis.text  = element_blank(),
        plot.title = element_text(hjust = 0.5,size = 12),
        legend.text = element_text(size = 9)) +
  coord_fixed(ratio = 1)
```

</center>

# Kappa

The level of agreement between rater A and rater B is the following:

```{r}
agree(full_array)
```

The Kappa statistic is the following:

```{r}
kappa2(full_array)
```

# Disagreements

## Relevant versus unreviewed

If there are any, the following are the articles for which one rater flagged 'relevant' and the other did not review it because it lay beyond the stop rule.

```{r}
if (missed1 == 0 & missed2 == 0) {
  print("There were no articles for which one rater flagged 'relevant' and the other did not review it.")
} else {
  compare_df %>% 
    filter(agreement_number == 1001) %>%
    select(-agreement_number) %>% 
    mutate(publication_year = str_remove_all(publication_year, "///")) %>% # Only
    kable(col.names = c("id", "author(s)", "year", "title", "abstract")) %>%
  kable_styling()
  
}
```

## Rater A

Studies for which  rater A flagged relevant and rater B flagged irrelevant.

```{r}
# Here, note that ASReview updated their default column names late-2021. 
# If your project is newer (late-2021 onward) then comment out the mutate() line.

disagree1_df %>% 
  mutate(publication_year = str_remove_all(publication_year, "///")) %>% # Only needed for older projects.
  kable(col.names = c("id", "author(s)", "year", "title", "abstract")) %>%
  # scroll_box(width = "120%", height = "300px") %>% 
  kable_styling()
```

<br>

<br>

## Rater B

Studies for which  rater B flagged relevant and rater A flagged irrelevant.

```{r}
# Here, note that ASReview updated their default column names late-2021. 
# If your project is newer (late-2021 onward) then comment out the mutate() line.

disagree2_df %>% 
  mutate(publication_year = str_remove_all(publication_year, "///")) %>% # Only needed for older projects.
  kable(col.names = c("id", "author(s)", "year", "title", "abstract")) %>% 
  # scroll_box(width = "120%", height = "300px") %>%
  kable_styling()
```

