---
title: "ASReview report"
output:
  # word_document:
  #   toc: yes
  #   toc_depth: '3'
  html_document:
    toc: yes
    toc_depth: 3
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, warning = F, message = F)
# Load packages.
library(readr)
library(dplyr)
library(stringr)
library(purrr)
library(irr)
library(kableExtra)
```

```{r start}
# Load data.
first_df <- read_csv("data/asreview_result_spatial-and-temporal-patterning-of-emergency-reactive-police-demand.csv")
secon_df <- read_csv("data/asreview_result_spatial-and-temporal-patterning-of-emergency-reactive-police-demand-2nd-coder.csv")

# Total reviewed.
first_total <- table(first_df$included)[[2]] + table(first_df$included)[[1]]
secon_total <- table(secon_df$included)[[2]] + table(secon_df$included)[[1]]

# Relevant flags.
first_rele <- table(first_df$included)[[2]]
first_irre <- table(first_df$included)[[1]]

# Irrelevant flags.
secon_rele <- table(secon_df$included)[[2]]
secon_irre <- table(secon_df$included)[[1]]

# Not reviewed
first_unrev <- sum(is.na(first_df$included))
secon_unrev <- sum(is.na(secon_df$included))

# % reviewed.
first_prev <- round(100*first_total/nrow(first_df), 2)
secon_prev <- round(100*secon_total/nrow(secon_df), 2)

# Total irrelevant.
first_trele <- first_irre + first_unrev
secon_trele <- secon_irre + secon_unrev

# % total relevant.
first_ptrel <- round(100*first_rele/nrow(first_df), 2)
secon_ptrel <- round(100*secon_rele/nrow(secon_df), 2)

# % flagged relevant.
first_pfrel <- round(100*first_rele/first_total, 2)
secon_pfrel <- round(100*secon_rele/secon_total, 2)

# Recode 'not rated' as irrelevant in each data frame.
first_rec_df <- first_df %>%
  mutate(included_rec = if_else(is.na(included), true = 0, false = included))

secon_rec_df <- secon_df %>%
  mutate(included_rec = if_else(is.na(included), true = 0, false = included))


# Disagreements 1: first coder says irrelevant, second coder says relevant.
first_irrelevant_vec <- first_rec_df %>% 
  filter(included == 0) %>% 
  pluck("record_id")

# Here, note that ASReview updated their default column names late-2021. Choose the relevant select() option for your data.
disagree1_df <- secon_rec_df %>% 
  filter(included == 1, record_id %in% first_irrelevant_vec) %>% 
  # select(record_id, authors, year, title, abstract) # For newer projects.
  select(record_id, first_authors, publication_year, primary_title, notes_abstract) # For older projects.

first_dis <- nrow(disagree1_df) # 6

# Disagreement 2: second coder says irrelevant, first coder says relevant.

secon_irrelevant_vec <- secon_rec_df %>% 
  filter(included == 0) %>% 
  pluck("record_id")

# Here, note that ASReview updated their default column names late-2021. Choose the relevant select() option for your data.
disagree2_df <- first_rec_df %>% 
  filter(included == 1, record_id %in% secon_irrelevant_vec) %>% 
  # select(record_id, authors, year, title, abstract) # For newer projects.
  select(record_id, first_authors, publication_year, primary_title, notes_abstract) # For older projects.

secon_dis <- nrow(disagree2_df) # 39

# Sort and create vectors for Kappa.
first_vec <- first_rec_df %>% 
  arrange(record_id) %>% 
  pluck("included")

secon_vec <- secon_rec_df %>% 
  arrange(record_id) %>% 
  pluck("included")

# Create array for Kappa.
full_array <- cbind(first_vec, secon_vec)

# Further disgareement statistics.

# Identify those which each reviewer did not even look at.
first_dist_vec <- first_rec_df %>% 
  # filter(included == 3) %>% 5 Dec 2023 change.
  filter(is.na(included)) %>%
  pluck("record_id")

secon_dist_vec <- secon_rec_df %>% 
  # filter(included == 3) %>% 5 Dec 2023 change.
  filter(is.na(included)) %>%
  pluck("record_id")

# Identify those relevant by one rather, and unreviewed by the other.
first_dist_df <- first_rec_df %>% 
  filter(included == 1) %>% 
  mutate(missed = if_else(record_id %in% secon_dist_vec,
                          "missed",
                          "not missed"))

secon_dist_df <- secon_rec_df %>% 
  filter(included == 1) %>% 
  mutate(missed = if_else(record_id %in% first_dist_vec,
                          "missed",
                          "not missed"))

# How many studies did one rather say *relevcant* and the other reviewer
# not even review?
missed1 <- nrow(first_dist_df) - table(first_dist_df$missed)[["not missed"]]
missed2 <- nrow(secon_dist_df) - table(secon_dist_df$missed)[["not missed"]]
```

# Rater summary

|                          | rater A            | rater B            |
| ------------------------ |:------------------:| ------------------:|
| n uploaded               | `r nrow(first_df)` | `r nrow(secon_df)` |
| n reviewed               | `r first_total`    | `r secon_total`    |
| % reviewed               | `r first_prev`     | `r secon_prev`     |
| n flagged relevant       | `r first_rele`     | `r secon_rele`     |
| n flagged irrelevant     | `r first_irre`     | `r secon_irre`     |
| % flagged relevant       | `r first_pfrel`    | `r secon_pfrel`    |
| n unreviewed             | `r first_unrev`    | `r secon_unrev`    |
| n total irrelevant       | `r first_trele`    | `r secon_trele`    |
| % total relevant         | `r first_ptrel`    | `r secon_ptrel`    |
| n relevant v. irrelevant | `r first_dis`      | `r secon_dis`      | 
| n relevant v. unreviewed | `r missed1`        | `r missed2`        | 

# Overall summary

```{r additionaltable}
# Remove the notes col
secon_df <- secon_df %>% 
  # select(-exported_notes_1) %>%      # add if needed.
  mutate(rater_id = 2) 
  # rename(record_id = `Ã¯..record_id`) # add if needed.

# Create rater id for the first rater.
first_df <- first_df %>% 
  mutate(rater_id = 1)

# Bind together.
first_secon_review_df <- bind_rows(first_df, secon_df) %>% 
  mutate(included_new = if_else(is.na(included), 1000, included))

# Create summary table.
compare_df <- first_secon_review_df %>% 
  # group_by(record_id, title) %>%       # add if needed. 
  group_by(record_id, primary_title) %>% # comment out if needed.
  summarise(agreement_number = sum(included_new)) %>% 
  ungroup()

# Check counts.


# Summary table.
table2_summary_df <- count(compare_df, agreement_number) %>%
  mutate(stat = ifelse(agreement_number == 0   , "Both rated irrelevant"                      , NA),
         stat = ifelse(agreement_number == 1   , "One rated relevant, other irrelevant"       , stat),
         stat = ifelse(agreement_number == 2   , "Both rated relevant"                        , stat),
         stat = ifelse(agreement_number == 1000, "One rated irrelevant, other left unreviewed", stat),
         stat = ifelse(agreement_number == 1001, "One rated relevant, other left unreviewed"  , stat),
         stat = ifelse(agreement_number == 2000, "Both left unreviewed"                       , stat)) %>% 
  select(stat, n) %>% 
  rename(Description = stat)

kable(table2_summary_df)
```

<!-- - Reviewer A evaluated `r first_total` of `r nrow(first_df)` articles, of which (s)he found `r first_rele` relevant. -->
<!-- - Reviewer B evaluated `r secon_total` of `r nrow(secon_df)` articles, of which (s)he found `r secon_rele` relevant. -->
<!-- - The reviewers evaluated xxx of the same articles. Of these articles there was 81.9% agreement on the evaluation of them. -->

<!-- - 416/612 both evaluated as irrelevant, 85/612 both evaluated as relevant, and 111/612 evaluated one as relevant and xxx as irrelevant.  -->
<!-- - In total 905/15530 articles were evaluated by at least one of the reviewers.   -->
<!--  - Reviewer A evaluated 191 articles (803-612) that Reviewer B did not evaluated. Of the 191 articles, Reviewer A evaluated 15 of these unseen articles by Reviewer B as relevant. -->
<!-- - Reviewer B evaluated 102 articles (714-612) that Reviewer A did not evaluated. Of the 102 articles, Reviewer B evaluated 0 of these unseen articles by Reviewer A as relevant. -->
<!--  - Reviewer A evaluated 131 (131-0) of the 131 relevant articles of Reviewer B, Reviewer A disagreed on 65: (s)he evaluated 65 of these as irrelevant. Reviewer A agreed on 66 (131-65-0): both reviewers thought these articles were relevant. All unevaluated articles by Reviewer A, in this case 0, were evaluated relevant by Reviewer B. -->
<!-- - Reviewer B evaluated 150 (165-15) of the 165 relevant articles of Reviewer A, Reviewer B disagreed on 46: (s)he evaluated 46 as irrelevant. Reviewer B agreed on 104 (165-46-15): both reviewers thought these articles were relevant. All unevaluated articles by Reviewer B, in this case 15, were evaluated relevant by Reviewer A.   -->


```{r irrdatasave}
irr_df <- tibble(
  ` ` = c("n uploaded", 
                "n reviewed",
                "% reviewed",
                "n flagged relevant",
                "n flagged irrelevant",
                "% flagged relevant",
                "n unreviewed",
                "n total irrelevant",
                "% total relevant",
                "n relevant v. irrelevant",
                "n relevant v. unreviewed"),
  `rater A` = c(nrow(first_df),
                first_total,
                first_prev,
                first_rele,
                first_irre,
                first_pfrel,
                first_unrev,
                first_trele,
                first_ptrel,
                first_dis,
                missed1),
  `rater B` = c(nrow(secon_df),
                secon_total,
                secon_prev,
                secon_rele,
                secon_irre,
                secon_pfrel,
                secon_unrev,
                secon_trele,
                secon_ptrel,
                secon_dis,
                missed2)
  )

write_csv(x = irr_df, file = "data/irr_table.csv")

```

# Kappa

The level of agreement between rater A and rater B, assuming that unreviewed articles are irrelevant, is the following:

```{r}
agree(full_array)
```

The Kappa statistic is the following:

```{r}
kappa2(full_array)
```

# Disagreements

## Rater A

Studies for which  rater A flagged relevant and rater B flagged irrelevant.

```{r}
# Here, note that ASReview updated their default column names late-2021. 
# If your project is newer (late-2021 onward) then comment out the mutate() line.

disagree2_df %>% 
  # mutate(publication_year = str_remove_all(publication_year, "///")) %>% # Only needed for older projects.
  kable(col.names = c("id", "author(s)", "year", "title", "abstract")) %>%
  # scroll_box(width = "120%", height = "300px") %>% 
  kable_styling()
```

<br>

<br>

## Rater B

Studies for which  rater B flagged relevant and rater A flagged irrelevant.

```{r}
# Here, note that ASReview updated their default column names late-2021. 
# If your project is newer (late-2021 onward) then comment out the mutate() line.

disagree1_df %>% 
  # mutate(publication_year = str_remove_all(publication_year, "///")) %>% # Only needed for older projects.
  kable(col.names = c("id", "author(s)", "year", "title", "abstract")) %>% 
  # scroll_box(width = "120%", height = "300px") %>% 
  kable_styling()
```

